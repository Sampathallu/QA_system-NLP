{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'DT')]\n",
      "[('middle', 'NN')]\n",
      "[('school', 'NN')]\n",
      "[('Liverpool', 'NNP'), (',', ',')]\n",
      "[('Nova', 'NNP')]\n",
      "[('Scotia', 'NN')]\n",
      "[('pumping', 'VBG')]\n",
      "[('bodies', 'NNS')]\n",
      "[('well', 'RB')]\n",
      "[('minds', 'NNS'), ('.', '.')]\n",
      "[('It', 'PRP'), (\"'s\", 'VBZ')]\n",
      "[('example', 'NN')]\n",
      "[('school', 'NN')]\n",
      "[('teaming', 'VBG')]\n",
      "[('community', 'NN')]\n",
      "[('raise', 'NN')]\n",
      "[('money', 'NN'), ('.', '.')]\n",
      "[('South', 'NNP')]\n",
      "[('Queens', 'NNS')]\n",
      "[('Junior', 'JJ')]\n",
      "[('High', 'JJ')]\n",
      "[('School', 'NN')]\n",
      "[('taking', 'VBG')]\n",
      "[('aim', 'NN')]\n",
      "[('fitness', 'NN')]\n",
      "[('market', 'NN'), ('.', '.')]\n",
      "[('The', 'DT')]\n",
      "[('school', 'NN')]\n",
      "[('turned', 'VBD')]\n",
      "[('one-time', 'NN')]\n",
      "[('metal', 'NN')]\n",
      "[('shop', 'NN')]\n",
      "[('-', ':')]\n",
      "[('lost', 'VBN')]\n",
      "[('budget', 'NN')]\n",
      "[('cuts', 'NNS')]\n",
      "[('almost', 'RB')]\n",
      "[('two', 'CD')]\n",
      "[('years', 'NNS')]\n",
      "[('ago', 'RB')]\n",
      "[('-', ':')]\n",
      "[('money-making', 'NN')]\n",
      "[('professional', 'JJ')]\n",
      "[('fitness', 'NN')]\n",
      "[('club', 'NN'), ('.', '.')]\n",
      "[('The', 'DT')]\n",
      "[('club', 'NN')]\n",
      "[('open', 'JJ')]\n",
      "[('seven', 'CD')]\n",
      "[('days', 'NNS')]\n",
      "[('week', 'NN'), ('.', '.')]\n",
      "[('The', 'DT')]\n",
      "[('club', 'NN'), (',', ',')]\n",
      "[('operated', 'VBN')]\n",
      "[('non-profit', 'JJ')]\n",
      "[('society', 'NN')]\n",
      "[('made', 'VBN')]\n",
      "[('school', 'NN')]\n",
      "[('community', 'NN')]\n",
      "[('volunteers', 'NNS'), (',', ',')]\n",
      "[('sold', 'VBN')]\n",
      "[('30', 'CD')]\n",
      "[('memberships', 'NNS')]\n",
      "[('hired', 'VBN')]\n",
      "[('full-time', 'NN')]\n",
      "[('co-ordinator', 'NN'), ('.', '.')]\n",
      "[('Principal', 'NN')]\n",
      "[('Betty', 'NNS')]\n",
      "[('Jean', 'NN')]\n",
      "[('Aucoin', 'NN')]\n",
      "[('says', 'VBZ')]\n",
      "[('club', 'NN')]\n",
      "[('first', 'RB')]\n",
      "[('Nova', 'NNP')]\n",
      "[('Scotia', 'NN')]\n",
      "[('public', 'NN')]\n",
      "[('school', 'NN'), ('.', '.')]\n",
      "[('She', 'PRP')]\n",
      "[('says', 'VBZ')]\n",
      "[('school', 'NN')]\n",
      "[('took', 'VBD')]\n",
      "[('provide', 'NN')]\n",
      "[('service', 'NN')]\n",
      "[('needed', 'VBN')]\n",
      "[('Liverpool', 'NNP'), ('.', '.')]\n",
      "[('``', '``'), ('We', 'PRP')]\n",
      "[('athletic', 'JJ')]\n",
      "[('facilities', 'NNS')]\n",
      "[('South', 'NNP')]\n",
      "[('Shore', 'NN')]\n",
      "[('Nova', 'NNP')]\n",
      "[('Scotia', 'NNP'), (',', ',')]\n",
      "[('use', 'NN')]\n",
      "[('schools', 'NNS'), (',', ',')]\n",
      "[('communities', 'NNS')]\n",
      "[('Queens', 'NNS')]\n",
      "[('going', 'VBG')]\n",
      "[('struggling', 'VBG')]\n",
      "[('get', 'VB')]\n",
      "[('anything', 'NN')]\n",
      "[('going', 'VBG'), (',', ','), (\"''\", \"''\")]\n",
      "[('Aucoin', 'NN')]\n",
      "[('said', 'VBD'), ('.', '.')]\n",
      "[('More', 'RBR')]\n",
      "[('$', '$'), ('100,000', 'CD')]\n",
      "[('raised', 'VBN')]\n",
      "[('fund-raising', 'NN')]\n",
      "[('donations', 'NNS')]\n",
      "[('government', 'NN'), (',', ',')]\n",
      "[('Sport', 'NN')]\n",
      "[('Nova', 'NNP')]\n",
      "[('Scotia', 'NNP'), (',', ',')]\n",
      "[('two', 'CD')]\n",
      "[('local', 'JJ')]\n",
      "[('companies', 'NNS'), ('.', '.')]\n",
      "[('Some', 'DT')]\n",
      "[('people', 'NNS')]\n",
      "[('wondering', 'VBG')]\n",
      "[('ties', 'NNS')]\n",
      "[('businesses', 'NNS')]\n",
      "[('school', 'NN')]\n",
      "[('close', 'RB'), ('.', '.')]\n",
      "[('Schools', 'NNS')]\n",
      "[('set', 'NN')]\n",
      "[('make', 'VB')]\n",
      "[('profits', 'NNS')]\n",
      "[('promote', 'NN')]\n",
      "[('businesses', 'NNS'), ('.', '.')]\n",
      "[('Southwest', 'NN')]\n",
      "[('Regional', 'JJ')]\n",
      "[('School', 'NN')]\n",
      "[('Board', 'NNP')]\n",
      "[('superintendent', 'NN')]\n",
      "[('Ann', 'NN')]\n",
      "[('Jones', 'NNP')]\n",
      "[('says', 'VBZ')]\n",
      "[('there', 'EX'), (\"'s\", 'VBZ')]\n",
      "[('fear', 'NN')]\n",
      "[('lines', 'NNS')]\n",
      "[('education', 'NN')]\n",
      "[('business', 'NN')]\n",
      "[('blurring', 'NN'), ('.', '.')]\n",
      "[('``', '``'), ('First', 'RB')]\n",
      "[('call', 'NN')]\n",
      "[('school', 'NN')]\n",
      "[('facility', 'NN')]\n",
      "[('belongs', 'NNS')]\n",
      "[('to', 'TO'), ('...', ':')]\n",
      "[('youngsters', 'NNS')]\n",
      "[('school', 'NN'), (',', ','), (\"''\", \"''\")]\n",
      "[('says', 'VBZ')]\n",
      "[('Ann', 'NN')]\n",
      "[('Jones', 'NNP'), ('.', '.')]\n",
      "[('The', 'DT')]\n",
      "[('12,000-square-foot', 'JJ')]\n",
      "[('club', 'NN')]\n",
      "[('seven', 'CD')]\n",
      "[('aerobic', 'NN')]\n",
      "[('machines', 'NNS'), (',', ',')]\n",
      "[('including', 'VBG')]\n",
      "[('treadmills', 'NNS'), (',', ',')]\n",
      "[('steppers', 'NNS'), (',', ',')]\n",
      "[('stationary', 'JJ')]\n",
      "[('bicycles', 'NNS'), (',', ',')]\n",
      "[('well', 'RB')]\n",
      "[('weight', 'NN')]\n",
      "[('machines', 'NNS')]\n",
      "[('freeweights', 'NNS'), ('.', '.')]\n",
      "[('Memberships', 'NNS')]\n",
      "[('cost', 'NN')]\n",
      "[('$', '$'), ('180', 'CD')]\n",
      "[('year', 'NN')]\n",
      "[('adults', 'NNS')]\n",
      "[('$', '$'), ('135', 'CD')]\n",
      "[('students', 'NNS')]\n",
      "[('seniors', 'NNS'), ('.', '.')]\n",
      "[('Proceeds', 'NNS')]\n",
      "[('pay', 'NN')]\n",
      "[('salary', 'NN')]\n",
      "[('centre', 'NN')]\n",
      "[('co-ordinator', 'NN')]\n",
      "[('upkeep', 'JJ')]\n",
      "[('facility', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "def inputdata(filename):\n",
    "    sentences = list()\n",
    "    wordlist = list()\n",
    "    headerlist = list()\n",
    "#     base_path = \"/Users/sampath/Downloads/NLP/developset\"\n",
    "#     path_to_file = os.path.join(base_path, \"1999-W02-5.story\")\n",
    "    with open(filename) as fd:\n",
    "        for line in fd:\n",
    "            line = line.split()\n",
    "            sentences.append(line)\n",
    "        sentences = [x for x in sentences if x]\n",
    "    for idx,i in enumerate(sentences):\n",
    "#     res = list(set(i)^set(stopWordsList))\n",
    "        if(idx>=4):\n",
    "            for a in i:\n",
    "                wordlist.append(a)\n",
    "        else:\n",
    "            for a in i:\n",
    "                headerlist.append(a)\n",
    "    stpwrds = stopwordremoval(wordlist)\n",
    "    postagger(stpwrds)\n",
    "inputdata(\"/Users/sampath/Downloads/NLP/developset/1999-W02-5.story\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def stopwordremoval(wordlist):\n",
    "    stop_words = list(stopwords.words('English'))\n",
    "    x = [i for i in wordlist if i not in stop_words]\n",
    "    return x\n",
    "#     wordlist = list()\n",
    "#     for idx,i in enumerate(sentences):\n",
    "# #     res = list(set(i)^set(stopWordsList))\n",
    "#     if(idx>=4):\n",
    "#         for a in i:\n",
    "#             wordlist.append(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postagger(list):\n",
    "    for i in list:\n",
    "        text = word_tokenize(str(i))\n",
    "        print(nltk.pos_tag(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
