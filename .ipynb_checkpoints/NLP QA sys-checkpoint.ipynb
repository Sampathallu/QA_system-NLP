{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Q/A system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required files\n",
    "#Under the code, what could happen to a student who swears at a teacher?\n",
    "#one queestion with multiple type in it list below\n",
    "\n",
    "# How old was Willie when he died?\n",
    "# Under the code, what could happen to a student who swears at a teacher?\n",
    "# What happened in Europe and England when Geoffrey was nine years old?\n",
    "# What happened when the Teamsters tried to unionize a McDonald's in Montreal?\n",
    "# When is the deadline by which the school must decide whether to sign a five-year contract with YNN?\n",
    "# What do we call groups of people who are experts at ringing bells?\n",
    "# How long does it take for delta-9 tetrahydrocannabinol to be absorbed into the bloodstream when someone smokes marijuana?\n",
    "# Where was the court where the trial took place?\n",
    "# What did doctors discover when Tyrell returned to them for treatment?\n",
    "# Who was prime minister when John Crosbie was a minister?\n",
    "# Who was prime minister when John Crosbie was a minister?\n",
    "# How did Pascal Hudon react when he was set free from jail, according to his mother?\n",
    "# Who was who was chanting \"Shame on China\" on Wednesday?\n",
    "# What did Gretzky do when he saw a youngster's hand extended from the crowd?\n",
    "# What did the two students who did the shootings do as they moved through the school?\n",
    "# Where was Chad Harris when the tornado hit?\n",
    "# How did Bob Thomas What describe forest conditions right now?\n",
    "# Who said \"the effects were top notch\" when he was talking about \"The Phantom Menace\"?\n",
    "# What is the average age of people who watch TSN's professional wrestling shows?\n",
    "# When she was in school, what would Julie do instead of going to recess?\n",
    "# Where were the evacuees taken when the fire threatened their homes?\n",
    "# Which member of the Canadian Parliament said that Texas officials should ignore the argument that Faulder's rights were violated when he wasn't told he could contact Canadian consular officials when he was charged with murder?\n",
    "# Which member of the Canadian Parliament said that Texas officials should ignore the argument that Faulder's rights were violated when he wasn't told he could contact Canadian consular officials when he was charged with murder?\n",
    "# How does a doctor usually learn how to perform operations?\n",
    "# Where are all the places in the world mentioned in this article in which mosasaur bones been have been found?\n",
    "# What does it mean when a \"search and rescue\" mission becomes a \"search and recovery\" mission?\n",
    "# Why did the government place limits on how many fish can be caught?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7d56d52bb826>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global vars\n",
    "STORY = \".story\"\n",
    "ANSWERS = \".answers\"\n",
    "QUESTIONS = \".questions\"\n",
    "\n",
    "#questions constants\n",
    "QUESTION = \"Question\"\n",
    "QUESTION_ID = \"QuestionID\"\n",
    "DIFFICULTY = \"Difficulty\"\n",
    "\n",
    "QUESTION_TYPE = [\"who\", \"where\", \"what\", \"how\", \"why\", \"when\", \"whose\", \"which\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quesionType(ques):\n",
    "    flag = False\n",
    "    for questionWord in ques.split(\" \"):\n",
    "        if questionWord.lower() in QUESTION_TYPE:\n",
    "            #if flag:\n",
    "                #print(ques)\n",
    "            flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processData(dataFileName):\n",
    "    try:\n",
    "        dataFileObject = open(dataFileName, \"r\")\n",
    "    except:\n",
    "        print(\"file \"+dataFileName+\" missing\")\n",
    "        return\n",
    "    dataFile = \"\"\n",
    "    for dataLine in dataFileObject:\n",
    "        dataFile += dataLine\n",
    "    data = []\n",
    "    flag = False\n",
    "    text = \"\"\n",
    "    for dataSet in dataFile.split(\"\\n\\n\"):\n",
    "        dataAttr = {} \n",
    "        for attr in dataSet.split(\"\\n\"):\n",
    "            if flag:\n",
    "                text += attr\n",
    "                continue\n",
    "            if len(attr.split(\":\")) == 2:\n",
    "                if attr.split(\":\")[0] == \"TEXT\":\n",
    "                    flag = True\n",
    "                    continue\n",
    "                dataAttr[attr.split(\":\")[0]] = attr.split(\":\")[1].strip() \n",
    "        if dataAttr != {}:\n",
    "            data.append(dataAttr)\n",
    "    if flag:\n",
    "        data[0][\"TEXT\"] = text\n",
    "    return data               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None # for easy if-statement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(data):\n",
    "#     data = data.translate(None, '!@#$\",')\n",
    "#     data = data.translate(None, \"'\")\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    dataWords = word_tokenize(data)\n",
    "    return [w for w in dataWords if not w in stop_words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictAns(ques, story):\n",
    "    stopWordsRemovedQuestionWords = removeStopWords(ques[\"Question\"])\n",
    "    stopWordsRemovedQWords = ques[\"Question\"].split(\" \")\n",
    "    para = story[\"TEXT\"]\n",
    "    maxSymanticReationScore = 0\n",
    "    maxScoreLine = \"\"\n",
    "    nlp = spacy.load('en_core_web_md') \n",
    "#     para = \"A middle school in Liverpool, Nova Scotia is pumping up bodies as well as minds. It's an example of a school teaming up with the community to raise money. South Queens Junior High School is taking aim at the fitness market. The school has turned its one-time metal shop - lost to budget cuts almost two years ago - into a money-making professional fitness club. The club will be open seven days a week. The club, operated by a non-profit society made up of school and community volunteers, has sold more than 30 memberships and hired a full-time co-ordinator. Principal Betty Jean Aucoin says the club is a first for a Nova Scotia public school. She says the school took it on itself to provide a service needed in Liverpool. 'We don't have any athletic facilities here on the South Shore of Nova Scotia, so if we don't use our schools, communities such as Queens are going to be struggling to get anything going,' Aucoin said. More than a $100,000 was raised through fund-raising and donations from government, Sport Nova Scotia, and two local companies. Some people are wondering if the ties between the businesses and the school are too close. Schools are not set up to make profits or promote businesses. Southwest Regional School Board superintendent Ann Jones says there's no fear the lines between education and business are blurring. 'First call on any school facility belongs to... the youngsters in the school,' says Ann Jones. The 12,000-square-foot club has seven aerobic machines, including treadmills, steppers, and stationary bicycles, as well as weight machines and freeweights. Memberships cost $180 a year for adults and $135 for students and seniors. Proceeds pay the salary of the centre co-ordinator and upkeep of the facility.\"\n",
    "    for paraLine in para.strip(\" \").split(\".\"):\n",
    "        symanticReationScore = 0\n",
    "        if paraLine != \"\":\n",
    "            stopWordsRemovedParaWords = removeStopWords(paraLine.strip(\" \"))\n",
    "            for qWord in stopWordsRemovedQWords:\n",
    "                for pWord in stopWordsRemovedParaWords:\n",
    "                    qWord = qWord.strip(\" \")\n",
    "                    pWord = pWord.strip(\" \")\n",
    "                    qWordSynsets = wordnet.synsets(qWord)\n",
    "                    pWordSynsets = wordnet.synsets(pWord)\n",
    "                    if qWord == pWord:\n",
    "                        symanticReationScore += 1 \n",
    "                    elif qWord and pWord and len(qWord)>0 and len(pWord)>0 and len(qWordSynsets) > 0 and len(pWordSynsets) > 0:\n",
    "                        if len(qWordSynsets)> 0 and len(pWordSynsets) > 0 :\n",
    "                            try:\n",
    "                                symanticReationScore += (qWordSynsets[0]).wup_similarity(pWordSynsets[0])\n",
    "                            except:\n",
    "                                continue\n",
    "            for qWord in nlp(\" \".join(stopWordsRemovedQWords)):\n",
    "                for pWord in nlp(\" \".join(stopWordsRemovedParaWords)):\n",
    "                    print(qWord, pWord, qWord.similarity(pWord))\n",
    "            if maxSymanticReationScore < symanticReationScore:\n",
    "                maxScoreLine = paraLine\n",
    "                maxSymanticReationScore = symanticReationScore\n",
    "#     print(\"----------------------\")\n",
    "#     print(ques[\"Question\"])\n",
    "#     print(maxScoreLine)\n",
    "#     print(\"symantic realtion\" + str(maxSymanticReationScore))\n",
    "#     print(\"----------------------\")\n",
    "    return maxScoreLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fscore(predictedAns, goldenAnswers):\n",
    "    maxFScore = 0\n",
    "    maxRecall = 0\n",
    "    predictedAns = predictedAns.strip()\n",
    "    for ans in goldenAnswers.split('|'):\n",
    "        ans = ans.strip()\n",
    "        if ans != \"\":\n",
    "            fScore = 0\n",
    "            noOfCorrectWords = len(list(set(ans.split(\" \")) & set(predictedAns.split(\" \"))))\n",
    "            recall = noOfCorrectWords / len(ans.split(\" \"))\n",
    "            precision = noOfCorrectWords / len(predictedAns.split(\" \"))\n",
    "            if recall != 0 and precision != 0:\n",
    "                fScore = (2 * recall * precision)/(recall + precision)\n",
    "            if fScore > maxFScore:\n",
    "                maxFScore = fScore\n",
    "                maxRecall = recall\n",
    "    return (maxFScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGoldenAns(goldenAnswers, questionID):\n",
    "    for ans in goldenAnswers:\n",
    "        if ans['QuestionID'] == questionID:\n",
    "            return ans\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictAnsForQuestionSet(dirPath, dataFileName):\n",
    "    questions =  processData(dirPath+dataFileName+QUESTIONS)\n",
    "    goldenAnswers =  processData(dirPath+dataFileName+ANSWERS)\n",
    "    story =  processData(dirPath+dataFileName+STORY)[0]\n",
    "    x = 0\n",
    "    avg = 0\n",
    "    for ques in questions:\n",
    "        if QUESTION in ques.keys():\n",
    "            goldenAns = getGoldenAns(goldenAnswers, ques['QuestionID'])\n",
    "            quesionType(ques[QUESTION])\n",
    "            predictedAns = predictAns(ques, story)\n",
    "#             print(\"QuestionID: \"+ ques['QuestionID'])\n",
    "#             print(\"Answer: \"+ predictedAns)\n",
    "#             print(\"Answer: \"+ goldenAns['Answer'])\n",
    "            if x == 100:\n",
    "                break\n",
    "            x += 1\n",
    "            avg += fscore(predictedAns.strip(), goldenAns['Answer'].strip())\n",
    "#             print(\"f-score: \" + str())\n",
    "#             print(\"f-score: \" + str(fscore(\"Elvis is great\", \"Elvis Presley |\")))\n",
    "#             print(\"\\n\")\n",
    "    print(avg/x)\n",
    "    return avg/x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.041666666666666664\n",
      "0.020243846330802853\n",
      "0.1330246913580247\n",
      "0.04926108374384237\n",
      "0.02580645161290323\n",
      "0.0\n",
      "0.009523809523809523\n",
      "0.0\n",
      "0.06666666666666667\n",
      "0.07692111209352588\n",
      "0.012345679012345678\n",
      "0.012549019607843137\n",
      "0.03272604588394062\n",
      "0.0\n",
      "0.0101010101010101\n",
      "0.03678678678678678\n",
      "0.0\n",
      "0.027966742252456538\n",
      "0.0\n",
      "0.15045255421599507\n",
      "0.0\n",
      "0.1626920306080726\n",
      "0.04947433518862089\n",
      "0.010752688172043008\n",
      "0.036651583710407235\n",
      "0.0\n",
      "0.02892361111111111\n",
      "0.058201058201058205\n",
      "0.10092905405405406\n",
      "0.012121212121212121\n",
      "0.015625\n",
      "0.037043829084907394\n",
      "0.08465608465608465\n",
      "0.05952380952380953\n",
      "0.02380952380952381\n",
      "0.014814814814814815\n",
      "0.04208754208754208\n",
      "0.043915343915343914\n",
      "0.0380952380952381\n",
      "0.014492753623188408\n",
      "0.0\n",
      "0.02724014336917563\n",
      "0.04601972101972102\n",
      "0.0\n",
      "0.07060395240976003\n",
      "0.05291666666666666\n",
      "0.07246376811594203\n",
      "0.06919642857142858\n",
      "0.08547959724430314\n",
      "0.034482758620689655\n",
      "0.01851851851851852\n",
      "0.02777777777777778\n",
      "0.03296703296703297\n",
      "0.044444444444444446\n",
      "0.0\n",
      "0.03636363636363636\n",
      "0.0\n",
      "0.03266227900374242\n",
      "0.05128205128205129\n",
      "0.06453634085213032\n",
      "0.11900584795321636\n",
      "0.11051693404634581\n",
      "0.04223521767381416\n",
      "0.049397150164413595\n",
      "0.0990127492644655\n",
      "0.09217506631299735\n",
      "0.1539673046251994\n",
      "0.1400383141762452\n",
      "0.04985994397759103\n",
      "0.0\n",
      "0.11165087568188344\n",
      "0.04009216589861751\n",
      "0.0441525269111476\n",
      "============\n",
      "0.045390687737116346\n"
     ]
    }
   ],
   "source": [
    "#harshi change it to arg and revrify the question ka input format\n",
    "questionsFileName = \"questions.txt\"\n",
    "questionsFile = open(questionsFileName, \"r\")\n",
    "\n",
    "count = 0\n",
    "dirPath = ''\n",
    "x = 0\n",
    "for questionsLine in questionsFile:\n",
    "    if count == 0:\n",
    "        dirPath = questionsLine[:-1]\n",
    "    else:\n",
    "        x += predictAnsForQuestionSet(dirPath, questionsLine[:-1])\n",
    "#     if count == 2:\n",
    "#         break\n",
    "    count += 1\n",
    "print(\"============\")\n",
    "print(x/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be.v.01'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet.synsets(\"is\")[0].name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fscoe 0.07351590231765104 synset  without word len avg\n",
    "\n",
    "\n",
    "fscoe 0.06876090488535765 synset  with word len avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
